#!/usr/bin/env python3
"""
è¯å…¸å¯¼å…¥è„šæœ¬ - å°†é«˜ä¸­ã€è€ƒç ”ã€æ‰˜ç¦è¯æ±‡å¯¼å…¥åˆ°Supabaseæ•°æ®åº“
"""

import os
import re
from supabase import create_client, Client
from typing import List, Dict, Optional

# ä»ç¯å¢ƒå˜é‡è·å–Supabaseé…ç½®
SUPABASE_URL = os.getenv("VITE_SUPABASE_URL")
SUPABASE_KEY = os.getenv("VITE_SUPABASE_ANON_KEY")

# è¯å…¸æ–‡ä»¶é…ç½®
DICT_FILES = {
    "é«˜ä¸­": "scripts/data/2_é«˜ä¸­-ä¹±åº copy.txt",
    "è€ƒç ”": "scripts/data/5_è€ƒç ”-ä¹±åº copy.txt",
    "æ‰˜ç¦": "scripts/data/6_æ‰˜ç¦-ä¹±åº copy.txt",
}


def init_supabase() -> Client:
    """åˆå§‹åŒ–Supabaseå®¢æˆ·ç«¯"""
    if not SUPABASE_URL or not SUPABASE_KEY:
        raise ValueError("è¯·è®¾ç½® VITE_SUPABASE_URL å’Œ VITE_SUPABASE_ANON_KEY ç¯å¢ƒå˜é‡")
    return create_client(SUPABASE_URL, SUPABASE_KEY)


def parse_line(line: str) -> Optional[Dict[str, str]]:
    """
    è§£ætxtæ–‡ä»¶ä¸­çš„ä¸€è¡Œ
    æ ¼å¼ï¼šå•è¯ TAB è¯æ€§. é‡Šä¹‰; æ›´å¤šé‡Šä¹‰

    è¿”å›: {"word": "å•è¯", "definition": "ä¸­æ–‡é‡Šä¹‰"}
    """
    parts = line.strip().split('\t')
    if len(parts) < 2:
        return None

    word = parts[0].strip()
    definition_raw = parts[1].strip()

    if not word:
        return None

    # æå–ä¸­æ–‡é‡Šä¹‰ï¼ˆå»é™¤è¯æ€§æ ‡è®°ï¼‰
    # ä¾‹å¦‚ï¼š"n. åŠªåŠ›ï¼›æˆå°±" -> "åŠªåŠ›ï¼›æˆå°±"
    definition = definition_raw

    return {
        "word": word,
        "definition": definition
    }


def load_dict_file(file_path: str) -> List[Dict[str, str]]:
    """è¯»å–å¹¶è§£æè¯å…¸æ–‡ä»¶"""
    words = []

    if not os.path.exists(file_path):
        print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return words

    with open(file_path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            parsed = parse_line(line)
            if parsed:
                words.append(parsed)

    return words


def import_words_with_tags(supabase: Client, words: List[Dict], source_tag: str):
    """
    å¯¼å…¥å•è¯åˆ°æ•°æ®åº“ï¼Œå¸¦æœ‰è¯æºæ ‡ç­¾

    ç­–ç•¥ï¼š
    1. æ£€æŸ¥å•è¯æ˜¯å¦å·²å­˜åœ¨
    2. å¦‚æœå­˜åœ¨ï¼Œæ›´æ–°source_tagsï¼ˆåˆå¹¶ä¸é‡å¤ï¼‰
    3. å¦‚æœä¸å­˜åœ¨ï¼Œæ’å…¥æ–°å•è¯
    """
    print(f"\nğŸ“š å¤„ç† [{source_tag}] è¯æ±‡...")
    print(f"   å…± {len(words)} ä¸ªå•è¯")

    # æ‰¹é‡æŸ¥è¯¢å·²å­˜åœ¨çš„å•è¯
    existing_words = {}
    word_list = [w["word"] for w in words]

    # åˆ†æ‰¹æŸ¥è¯¢ï¼ˆSupabaseæœ‰æŸ¥è¯¢é™åˆ¶ï¼‰
    batch_size = 100
    for i in range(0, len(word_list), batch_size):
        batch = word_list[i:i+batch_size]
        result = supabase.table("words_unified")\
            .select("word, source_tags")\
            .in_("word", batch)\
            .execute()

        for item in result.data:
            existing_words[item["word"]] = item.get("source_tags", [])

    # åˆ†ç±»ï¼šéœ€è¦æ’å…¥çš„å’Œéœ€è¦æ›´æ–°çš„
    to_insert = []
    to_update = []

    for word_data in words:
        word = word_data["word"]

        if word in existing_words:
            # å·²å­˜åœ¨ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ ‡ç­¾
            current_tags = existing_words[word] or []
            if source_tag not in current_tags:
                new_tags = current_tags + [source_tag]
                to_update.append({
                    "word": word,
                    "source_tags": new_tags
                })
        else:
            # æ–°å•è¯ï¼Œéœ€è¦æ’å…¥
            to_insert.append({
                "word": word.lower(),
                "display_word": word,
                "phonetic": "",
                "translation": word_data["definition"],
                "definition": word_data["definition"],
                "example": "",
                "source_tags": [source_tag],
                "is_ai_generated": False
            })

    print(f"   âœ¨ éœ€è¦æ’å…¥: {len(to_insert)} ä¸ª")
    print(f"   ğŸ”„ éœ€è¦æ›´æ–°æ ‡ç­¾: {len(to_update)} ä¸ª")

    # æ‰¹é‡æ’å…¥æ–°å•è¯
    if to_insert:
        batch_size = 50
        for i in range(0, len(to_insert), batch_size):
            batch = to_insert[i:i+batch_size]
            try:
                supabase.table("words_unified").insert(batch).execute()
                print(f"   âœ… å·²æ’å…¥ {min(i+batch_size, len(to_insert))}/{len(to_insert)}")
            except Exception as e:
                print(f"   âŒ æ‰¹æ¬¡ {i//batch_size + 1} æ’å…¥å¤±è´¥: {e}")

    # æ‰¹é‡æ›´æ–°æ ‡ç­¾
    if to_update:
        for item in to_update:
            try:
                supabase.table("words_unified")\
                    .update({"source_tags": item["source_tags"]})\
                    .eq("word", item["word"])\
                    .execute()
            except Exception as e:
                print(f"   âŒ æ›´æ–° {item['word']} æ ‡ç­¾å¤±è´¥: {e}")
        print(f"   âœ… å·²æ›´æ–° {len(to_update)} ä¸ªå•è¯çš„æ ‡ç­¾")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ“– è¯å…¸å¯¼å…¥å·¥å…·")
    print("=" * 60)

    # åˆå§‹åŒ–Supabase
    try:
        supabase = init_supabase()
        print("âœ… å·²è¿æ¥åˆ°Supabase")
    except Exception as e:
        print(f"âŒ è¿æ¥Supabaseå¤±è´¥: {e}")
        return

    # å¤„ç†æ¯ä¸ªè¯å…¸æ–‡ä»¶
    for source_tag, file_path in DICT_FILES.items():
        print(f"\n{'='*60}")
        print(f"å¤„ç†æ–‡ä»¶: {file_path}")
        print(f"è¯æºæ ‡ç­¾: {source_tag}")

        # è¯»å–æ–‡ä»¶
        words = load_dict_file(file_path)

        if not words:
            print(f"âš ï¸  æœªèƒ½ä» {file_path} è¯»å–åˆ°ä»»ä½•å•è¯ï¼Œè·³è¿‡...")
            continue

        # å¯¼å…¥åˆ°æ•°æ®åº“
        try:
            import_words_with_tags(supabase, words, source_tag)
        except Exception as e:
            print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
            continue

    print("\n" + "=" * 60)
    print("âœ¨ å¯¼å…¥å®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
